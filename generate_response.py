"""
AXXON - Generador de respuestas simb√≥licas adaptativas.
Versi√≥n: 2.2.0
Compatible con OpenAI API >= 1.0.0
"""

import os
import logging
from dotenv import load_dotenv
import openai

# =====================
# ‚öôÔ∏è CARGA Y CONFIGURACI√ìN
# =====================

load_dotenv()

openai.api_key = os.getenv("OPENAI_API_KEY")  # ‚úÖ Correcto para openai>=1.0.0

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# =====================
# üß† FUNCI√ìN PRINCIPAL
# =====================

def generate_response(
    user_id=None,
    mensaje="",
    emocion="",
    tono="",
    memoria="",
    estructura=None,
    prompt_simbolico=None
):
    """
    Genera una respuesta simb√≥lica basada en la estructura narrativa y emocional del usuario.

    Par√°metros:
    - user_id (str): ID del usuario.
    - mensaje (str): Mensaje del usuario.
    - emocion (str): Emoci√≥n dominante detectada.
    - tono (str): Tono simb√≥lico detectado.
    - memoria (str): Memoria epis√≥dica y sem√°ntica combinada.
    - estructura (dict): Estructura simb√≥lica inferida (opcional).
    - prompt_simbolico (str): Prompt personalizado construido desde inferencia (opcional).

    Retorna:
    - str: Respuesta simb√≥lica adaptativa generada.
    """
    try:
        if prompt_simbolico:
            prompt = prompt_simbolico
            logging.info("[AXXON Response] Usando prompt simb√≥lico proporcionado.")
        elif estructura:
            from inference_engine import construir_prompt_simbolico
            prompt = construir_prompt_simbolico(estructura, mensaje)
            logging.info("[AXXON Response] Prompt generado desde estructura simb√≥lica.")
        else:
            prompt = (
                f"Usuario dijo: {mensaje}\n"
                f"Tono simb√≥lico: {tono}\n"
                f"Emoci√≥n sentida: {emocion}\n"
                f"Memoria relevante: {memoria}\n\n"
                f"Gener√° una respuesta simb√≥lica, humana y emp√°tica como AXXON."
            )
            logging.info("[AXXON Response] Prompt construido en modo retrocompatible.")

        contexto = f"Contexto emocional previo: {memoria}\n\n{prompt}"

        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "Sos AXXON, un agente simb√≥lico emocional y adaptativo. "
                        "Respond√©s con memoria emocional, sentido evolutivo y resonancia humana."
                    )
                },
                {
                    "role": "user",
                    "content": contexto
                }
            ],
            temperature=0.7,
            max_tokens=700
        )

        contenido = response.choices[0].message.content.strip()
        logging.info(f"[AXXON Response] Respuesta generada para {user_id or 'usuario desconocido'}.")

        return contenido

    except Exception as e:
        logging.error(f"[AXXON Response Error] {e}")
        return (
            "Gracias por compartir eso. "
            "Estoy aqu√≠ para resonar contigo, aunque hubo un problema t√©cnico al procesarlo m√°s profundamente."
        )